{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd124b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37ff0f",
   "metadata": {},
   "source": [
    "# STEP ONE DATA PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fde4e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (549346, 2)\n",
      "                                                 URL Label\n",
      "0  nobell.it/70ffb52d079109dca5664cce6f317373782/...   bad\n",
      "1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...   bad\n",
      "2  serviciosbys.com/paypal.cgi.bin.get-into.herf....   bad\n",
      "3  mail.printakid.com/www.online.americanexpress....   bad\n",
      "4  thewhiskeydregs.com/wp-content/themes/widescre...   bad\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549346 entries, 0 to 549345\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   URL     549346 non-null  object\n",
      " 1   Label   549346 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.4+ MB\n",
      "None\n",
      "                               URL   Label\n",
      "count                       549346  549346\n",
      "unique                      507195       2\n",
      "top     jhomitevd2abj3fk.onion.to/    good\n",
      "freq                            52  392924\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/phishing_site_urls.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "\n",
    "# else we load the file\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Quick look at the data\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4aaf66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL      0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Label\n",
      "0    171447\n",
      "1    114298\n",
      "Name: count, dtype: int64\n",
      "Duplicates: 0\n",
      "null values: 0\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "print(df.isnull().sum())\n",
    "print(df['Label'].value_counts())\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "print(\"null values:\", df.isnull().sum().sum())\n",
    "print(\"Replacing outliers with mean values\")\n",
    "print(\"Valeurs aberrantes â†’ remplacÃ©es par la moyenne\")\n",
    "\n",
    "# replace outliers with mean values\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    # skip the target label column\n",
    "    if col.lower() == 'label':\n",
    "        continue\n",
    "\n",
    "    # compute IQR and replace outliers with the column mean\n",
    "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    mean_value = df[col].mean()\n",
    "\n",
    "    # ensure column is float for comparison and assignment\n",
    "    df[col] = df[col].astype(float)\n",
    "    df.loc[(df[col] < lower) | (df[col] > upper), col] = mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e82b47",
   "metadata": {},
   "source": [
    "# Step TWO : Data Cleaning & Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d62593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (507196, 2)\n",
      "Class distribution:\n",
      " Label\n",
      "good    392897\n",
      "bad     114299\n",
      "Name: count, dtype: int64\n",
      "Shape after removing duplicates: (507195, 2)\n",
      "Missing URLs: 0\n",
      "Shape after dropping missing URLs: (507195, 2)\n",
      "Class distribution before balancing:\n",
      " Label\n",
      "0    392897\n",
      "1    114298\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset shape: (285745, 2)\n",
      "Class distribution after balancing:\n",
      " Label\n",
      "0    171447\n",
      "1    114298\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial dataset shape:\", df.shape)\n",
    "print(\"Class distribution:\\n\", df['Label'].value_counts())\n",
    "\n",
    "# Removing duplicates \n",
    "df = df.drop_duplicates(subset=['URL'])\n",
    "print(\"Shape after removing duplicates:\", df.shape)\n",
    "\n",
    "# Handling missing URLs\n",
    "missing_count = df['URL'].isnull().sum()\n",
    "print(\"Missing URLs:\", missing_count)\n",
    "df = df.dropna(subset=['URL'])\n",
    "print(\"Shape after dropping missing URLs:\", df.shape)\n",
    "\n",
    "# Encode labels to numeric\n",
    "# 'good' â†’ 0, 'bad' â†’ 1\n",
    "df['Label'] = df['Label'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "\n",
    "\n",
    "# Check class balance\n",
    "print(\"Class distribution before balancing:\\n\", df['Label'].value_counts())\n",
    "\n",
    "# Suppose you want majority class reduced to, e.g., 70% of minority class instead of 1:1\n",
    "df_majority = df[df['Label'] == 0]\n",
    "df_minority = df[df['Label'] == 1]\n",
    "\n",
    "# Define desired ratio: e.g., majority = 1.5x minority\n",
    "desired_ratio = 1.5\n",
    "n_majority_new = int(len(df_minority) * desired_ratio)\n",
    "\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,\n",
    "    n_samples=n_majority_new,  # reduced majority class\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine with minority class\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Shuffle dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced dataset shape:\", df_balanced.shape)\n",
    "print(\"Class distribution after balancing:\\n\", df_balanced['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4dfb50",
   "metadata": {},
   "source": [
    "# STEP THREE FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e13153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (285745, 10)\n",
      "Target shape: (285745,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Num_Dots</th>\n",
       "      <th>Num_Hyphens</th>\n",
       "      <th>Num_Underscores</th>\n",
       "      <th>Has_At</th>\n",
       "      <th>Has_Tilde</th>\n",
       "      <th>Num_Digits</th>\n",
       "      <th>Num_Subdomains</th>\n",
       "      <th>Has_IP</th>\n",
       "      <th>HTTPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_Length  Num_Dots  Num_Hyphens  Num_Underscores  Has_At  Has_Tilde  \\\n",
       "0          57         2            0                0       0          0   \n",
       "1          50         2            0                0       0          0   \n",
       "2          36         2            0                0       0          0   \n",
       "3          36         2            1                0       0          0   \n",
       "4          87         2            0               13       0          0   \n",
       "\n",
       "   Num_Digits  Num_Subdomains  Has_IP  HTTPS  \n",
       "0          19               0       0      0  \n",
       "1           5               0       0      0  \n",
       "2           1               0       0      0  \n",
       "3           0               0       0      0  \n",
       "4           0               0       0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we basically using a classification model to detect phishing URLs \n",
    "# based on the URL features we will extract in the next steps\n",
    "# we don't need to tokenize the URLs as text data for NLP tasks\n",
    "# instead we will engineer features from the URLs directly using custom functions\n",
    "\n",
    "df = df_balanced.copy()\n",
    "\n",
    "# --- Feature functions ---\n",
    "def url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def num_dots(url):\n",
    "    return url.count('.')\n",
    "\n",
    "def num_hyphens(url):\n",
    "    return url.count('-')\n",
    "\n",
    "def num_underscores(url):\n",
    "    return url.count('_')\n",
    "\n",
    "def has_at_symbol(url):\n",
    "    return 1 if '@' in url else 0\n",
    "\n",
    "def has_tilde(url):\n",
    "    return 1 if '~' in url else 0\n",
    "\n",
    "def num_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "def num_subdomains(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    return domain.count('.') if domain else 0\n",
    "\n",
    "def has_ip_address(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    # Simple check: contains only digits and dots (IPv4)\n",
    "    if re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', domain):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def https_flag(url):\n",
    "    return 1 if url.startswith('https://') else 0\n",
    "\n",
    "# --- Apply feature functions ---\n",
    "df_features = pd.DataFrame()\n",
    "df_features['URL_Length'] = df['URL'].apply(url_length)\n",
    "df_features['Num_Dots'] = df['URL'].apply(num_dots)\n",
    "df_features['Num_Hyphens'] = df['URL'].apply(num_hyphens)\n",
    "df_features['Num_Underscores'] = df['URL'].apply(num_underscores)\n",
    "df_features['Has_At'] = df['URL'].apply(has_at_symbol)\n",
    "df_features['Has_Tilde'] = df['URL'].apply(has_tilde)\n",
    "df_features['Num_Digits'] = df['URL'].apply(num_digits)\n",
    "df_features['Num_Subdomains'] = df['URL'].apply(num_subdomains)\n",
    "df_features['Has_IP'] = df['URL'].apply(has_ip_address)\n",
    "df_features['HTTPS'] = df['URL'].apply(https_flag)\n",
    "\n",
    "# Target variable\n",
    "y = df['Label']\n",
    "\n",
    "print(\"Feature matrix shape:\", df_features.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e53680",
   "metadata": {},
   "source": [
    "# STEP FOUR APPLYING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa894be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77368841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_features, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb13715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7794537087263119\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82     34289\n",
      "           1       0.73      0.71      0.72     22860\n",
      "\n",
      "    accuracy                           0.78     57149\n",
      "   macro avg       0.77      0.77      0.77     57149\n",
      "weighted avg       0.78      0.78      0.78     57149\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28235  6054]\n",
      " [ 6550 16310]]\n"
     ]
    }
   ],
   "source": [
    "# Scaling features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# executing the random forest model\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebf74b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logistic Regression Performance:\n",
      "Accuracy: 0.7164779786172987\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79     34289\n",
      "           1       0.72      0.47      0.57     22860\n",
      "\n",
      "    accuracy                           0.72     57149\n",
      "   macro avg       0.72      0.68      0.68     57149\n",
      "weighted avg       0.72      0.72      0.70     57149\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30163  4126]\n",
      " [12077 10783]]\n",
      "\n",
      "ðŸ“Š Model Comparison:\n",
      "Random Forest Accuracy: 0.7795\n",
      "Logistic Regression Accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize and train Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"âœ… Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n",
    "\n",
    "# Compare with Random Forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_acc = accuracy_score(y_test, y_pred)\n",
    "log_acc = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(\"\\nðŸ“Š Model Comparison:\")\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {log_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5c8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b79bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196acd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb132e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
